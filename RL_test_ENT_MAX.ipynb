{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW DATA TEST\n",
    "caiso=pd.read_csv(\"/Users/john_schafer/Downloads/CE291/CAISO_zone_1_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform Data to our format\n",
    "caiso['time'] = pd.to_datetime(caiso['time'])\n",
    "caiso.set_index('time', inplace=True)\n",
    "\n",
    "# Function to reshape the data\n",
    "def reshape_data(df, column):\n",
    "    # Resample data to daily frequency, and apply list to convert each day's data into a list\n",
    "    daily_data = df[column].resample('D').apply(list)\n",
    "    # Convert lists to a DataFrame, which inherently transposes the list to columns\n",
    "    return pd.DataFrame(daily_data.tolist(), index=daily_data.index)\n",
    "\n",
    "# Creating each DataFrame\n",
    "demand_df = reshape_data(caiso, 'load_power')\n",
    "solar_df = reshape_data(caiso, 'solar_power')\n",
    "wind_df = reshape_data(caiso, 'wind_power')\n",
    "\n",
    "def rename_columns(df):\n",
    "    num_minutes = df.shape[1]\n",
    "    time_labels = [str(pd.Timedelta(minutes=i)) for i in range(num_minutes)]\n",
    "    df.columns = time_labels\n",
    "    return df\n",
    "\n",
    "demand_df = rename_columns(demand_df)\n",
    "solar_df = rename_columns(solar_df)\n",
    "wind_df = rename_columns(wind_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scaling \n",
    "# if power is normalized to 1, PEV dynamics in environment are run in kw\n",
    "#max power of single Ev = 11 kw \n",
    "#max power of representative small microgrid of 5,000 people ~ 3.5 megawatts=3,500 kw\n",
    "#multiply vby 3500 to get representative \n",
    "demand_caiso = np.array(demand_df)\n",
    "solar_caiso = np.array(solar_df)*3 \n",
    "wind_caiso = np.array(wind_df)*4 \n",
    "net_caiso=demand_caiso-solar_caiso-wind_caiso\n",
    "\n",
    "average_demand_per_minute = np.nanmean(demand_caiso, axis=0)\n",
    "average_solar_per_minute = np.nanmean(solar_caiso, axis=0)\n",
    "average_wind_per_minute = np.nanmean(wind_caiso, axis=0)\n",
    "\n",
    "average_net_per_minute=average_demand_per_minute-average_solar_per_minute-average_wind_per_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample only every ten minutes\n",
    "average_demand_10min= average_demand_per_minute[::10]\n",
    "average_solar_10min= average_solar_per_minute[::10]\n",
    "average_wind_10min= average_wind_per_minute[::10]\n",
    "\n",
    "average_net_10min=average_demand_10min-average_solar_10min-average_wind_10min\n",
    "\n",
    "average_demand_10min= average_demand_10min.reshape(144,1).T\n",
    "average_solar_10min=average_solar_10min.reshape(144,1).T\n",
    "average_wind_10min=average_wind_10min.reshape(144,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DQL_SOFT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDQL_SOFT\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menv_rnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridEnvironment\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DQL_SOFT'"
     ]
    }
   ],
   "source": [
    "from DQL_SOFT import DQNAgent\n",
    "from env_rnn import GridEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Max Entropy Technique\n",
    "import time\n",
    "timestep_length=(10/60) #in hours\n",
    "N=800\n",
    "sequence_length=12 #In timesteps aka minutes\n",
    "state_deque = deque(maxlen=sequence_length)\n",
    "\n",
    "day_index=0\n",
    "# Initialize DQN agent\n",
    "agent = DQNAgent(state_size=3, action_size=21, sequence_length=sequence_length)\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "for episode in range(50):  # Loop over 3 episodes of same \"average\" day\n",
    "    # Initialize environment for the current day\n",
    "    start_time = time.time()\n",
    "    env = GridEnvironment(N, average_demand_10min, average_solar_10min, average_wind_10min, day_index, timestep_length)\n",
    "    \n",
    "    total_reward = 0\n",
    "    T = 144  # Assume T timesteps in a day\n",
    "\n",
    "    demand_profile = np.zeros(T)\n",
    "    solar_profile = np.zeros(T)\n",
    "    wind_profile = np.zeros(T)\n",
    "    PEV_profile = np.zeros(T)\n",
    "\n",
    "    for timestep in range(1, T+1):  # Loop through each timestep in the day\n",
    "        normalized_timestep = np.array([timestep / T])   # T is the total number of timesteps in a day\n",
    "\n",
    "        current_demand, current_solar, current_wind, current_SoC = env.get_state()\n",
    "        current_P_EV=env.P_EV\n",
    "        current_state=np.concatenate([np.array([current_demand, current_solar, current_wind])])#, np.array(current_P_EV), normalized_timestep, current_SoC])\n",
    "\n",
    "        state_deque.append(current_state)\n",
    "        state_history = np.array(state_deque)\n",
    "\n",
    "        if len(state_deque) < sequence_length:\n",
    "            continue  # Wait until deque is full before starting training\n",
    "        \n",
    "        action = agent.act(state_history)  # Decide action based on current state\n",
    "        # Execute action in the environment and observe the next state, reward, and done flag\n",
    "        reward, done, next_demand, next_solar, next_wind, next_P_EV, next_SoC = env.step(action)\n",
    "\n",
    "        # Update profiles for plotting\n",
    "        demand_profile[timestep - 1] = next_demand\n",
    "        solar_profile[timestep - 1] = next_solar\n",
    "        wind_profile[timestep - 1] = next_wind\n",
    "        PEV_profile[timestep - 1] = np.sum(next_P_EV)\n",
    "        \n",
    "        normalized_next_timestep = np.array([(timestep+1) / T])\n",
    "        # Construct the new state from the separated components\n",
    "        next_state = np.concatenate([np.array([next_demand, next_solar, next_wind])])#, np.array(next_P_EV), normalized_next_timestep, next_SoC])\n",
    "        \n",
    "        # Directly learn from this transition without using replay\n",
    "        agent.learn(state_history, action, reward, next_state, done)\n",
    "\n",
    "        # Update state and total_reward\n",
    "        #state = next_state why did I have this?\n",
    "        total_reward += reward\n",
    "        \n",
    "\n",
    "        if done:\n",
    "            # Handle episode completion, if applicable\n",
    "            break\n",
    "\n",
    "    print(f\"Total reward for episode {episode}: {total_reward}\")\n",
    "    agent.epsilon=max(agent.epsilon_min, agent.epsilon * agent.epsilon_decay) \n",
    "    episode_durations.append(time.time() - start_time)\n",
    "print(\"Individual episode durations:\", episode_durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(demand_profile, label='Demand', color=\"red\")\n",
    "plt.plot(-1*solar_profile, label='Solar', color='green', marker='o')\n",
    "plt.plot(-1*wind_profile, label='Wind', color='green', marker='+')\n",
    "\n",
    "plt.plot(demand_profile+PEV_profile -solar_profile- wind_profile, label='NET=REWARD')\n",
    "\n",
    "# Plot the PEV_profile as a bar graph\n",
    "timesteps = np.arange(len(PEV_profile))  \n",
    "plt.bar(timesteps, PEV_profile, width=1.0, label='PEV', alpha=0.5)  \n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Energy Profiles for 2000th Episode')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Power')\n",
    "#plt.savefig('2000_RNN_perc_action.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('info251')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2064303d263e1a3ceaaf815227a08219bcf9396a8cb60113be5ce3b525cf3c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
